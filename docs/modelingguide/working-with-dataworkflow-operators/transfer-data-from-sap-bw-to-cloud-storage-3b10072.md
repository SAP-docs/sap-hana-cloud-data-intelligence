<!-- loio3b100723393b4a7d85e5c840f970550b -->

<link rel="stylesheet" type="text/css" href="../css/sap-icons.css"/>

# Transfer Data from SAP BW to Cloud Storage

Use the *Data Transfer* operator in a data workflow graph \(pipeline\) to transfer data from an SAP Business Warehouse \(BW\) system to cloud storage.



<a name="loio3b100723393b4a7d85e5c840f970550b__prereq_ot5_5yl_vdb"/>

## Prerequisites

Before you perform the following task, ensure that you've created the following connections using the SAP Data Intelligence Connection Management application:

-   Create a connection to an SAP BW system.
-   Create a connection to a cloud storage.

> ### Note:  
> SAP Data Intelligence displays decimal numbers from the source with the same scale as shown in other SAP tools, such as SAP Logon or SAP BW Modeling tools. SAP Data Intelligence represents the data in its raw form as generated by the SAP BW system and rounds it down to the nearest number based on the SAP BW backend scale.



## Context

In the Modeler, configure and execute the Data Transfer operator in a graph to transfer data from SAP BW to cloud storage. Run the data workflow using three access layers.



## Procedure

1.  Start the SAP Data Intelligence Modeler.

2.  Open the *Graphs* tab in the navigation pane.

3.  Select :heavy_plus_sign: in the navigation pane toolbar and choose *Use Generation 1 Operators*.

4.  Select the Data Transfer operator.

    A graph can contain a single operator or a network of operators based on the business requirement.

    1.  Open the *Operators* tab in the navigation pane.

    2.  Enter “Data Transfer” in the search bar in the navigation pane toolbar.

    3.  Double-click the Data Transfer operator in the search results.

        The Modeler adds the Data Transfer operator to the graph editor.

    4.  Double-click the Data Transfer operator in the graph editor.

        The Modeler opens a form-based editor where you define the source and target for data transfer


5.  Provide details of the source dataset for the data transfer operation.

    1.  Open the *Source* tab.

    2.  Browse for or enter a connection ID in the *Connection ID* text box.

        A connection ID provides the connection to an SAP BW system.

    3.  Browse for or enter the source in the *Source* text box.

        If you browse for the source, the *Browse File* dialog box contains all queries, InfoProviders, or DataStores from the SAP BW system used in the connection ID definition. Source types include the following:

        -   Queries
        -   InfoProviders
        -   DataStores


6.  **Optional:** Import source dataset \(Queries, InfoProviders, or DataStores\) from the Metadata Catalog.

    1.  Select *Import Dataset* in the *Source* tab.

    2.  Browse and select the required dataset.

    3.  Select *OK*.

        The Modeler populates the connection details automatically based on the selected data set.


7.  If you select a query as the source dataset, and if the query is defined with parameters, provide values to the parameters.

    The Modeler populates the default values automatically, if any, that are already defined for the parameters.

    1.  Select :pencil2: in the *Variables* text field.

    2.  Select the required parameter and operator type, and provide a value in the *Provide Parameter Values* dialog box.

    3.  **Optional:** To view the mandatory parameters only, select <span class="SAP-icons"></span> \(Add Filter\) and select *Show Mandatory Only*.

    4.  Select *OK*.


8.  **Optional:** Specify the transfer mode.

    SAP Data Intelligence supports three types of transfer modes. The preferred mode is to use SAP HANA.

    1.  If the engine uses the SAP BW OLAP \(Online Analytical Processing\) Interface Information Access Protocol \(INA\) to retrieve data from the source, enter a value in milliseconds in *Timeout*

        The Modeler waits for the time that you specify before it times out on the data retrieval. After the timeout period, the graph execution fails. The default timeout value is 60 seconds.

    2.  To use an SAP HANA view, mark a specific query or InfoProvider in the query designer to generate an underlying Calculation view. SAP Data Intelligence can query this view to transfer the data to other target systems.

        If an external SAP HANA view exists, the Modeler displays the name of the SAP HANA view that it's using to retrieve data from the source.

        > ### Remember:  
        > The engine uses the nonoptimized SAP BW OLAP \(INA\) provider to retrieve data from the source only if no external SAP HANA view exists.


    If you select a DataStore, then the application by default uses SAP BW Operational Data Provisioning \(ODP\) as the Data Access configuration. In this case, you can't modify the access configuration.

9.  **Optional:** If you use SAP BW DataStore as a source, perform the following substeps:

    1.  Choose an extraction mode.

        Choose from one of the following extraction modes:

        -   *Full*: Extracts all data at once.
        -   *Delta*: Extracts only what has changed with each run of the graph.

    2.  If you choose *Full*, define a file as the target.

        The application supports two modes:


        <table>
        <tr>
        <th valign="top">

        Mode
        
        </th>
        <th valign="top">

        Description
        
        </th>
        </tr>
        <tr>
        <td valign="top">
        
        *Overwrite*
        
        </td>
        <td valign="top">
        
        Choose a file or a file name in the target file system. For each run, the Modeler overwrites the selected file.
        
        </td>
        </tr>
        <tr>
        <td valign="top">
        
        *Create for each package*
        
        </td>
        <td valign="top">
        
        Choose a file or pick a file name in the target file system. For each run, the Modeler writes a new file for each data package.
        
        </td>
        </tr>
        </table>
        
        > ### Note:  
        > The Modeler extracts the full data when you run the graph for the first time. After the first run, the Modeler extracts only delta changes for all subsequent runs.

    3.  Provide a subscription ID.

        Consider the following information about subscription IDs:

        -   The ID must be unique for the same InfoProvider in the same SAP BW system for all clients accessing it.
        -   For Full extraction mode, the system generates a subscription ID automatically.
        -   The ID serves as the session for the delta extraction and stores the delta pointer. It ensures that just the changed data is transferred.
        -   Write the subscription ID so that you can later look it up on your subscriptions.


10. Select the required measures and dimensions from the source dataset to project to the target.

    1.  Open the *Target* tab.

        The Modeler displays all measures and dimensions from the selected source in the *Column Mapping* section.

    2.  Drag and drop applicable source columns from the Source pane to the Target pane.

        > ### Note:  
        > When you map columns from source to target, or if there are pre-existing target objects that have the data types listed below, the Modeler reorders the columns in the target pane automatically based on those data types regardless of the target type.
        > 
        > The columns with the following data types appear at the end of the list in the target pane:
        > 
        > -   BLOB
        > -   CLOB
        > -   NCLOB
        > -   BINARY
        > -   VARBINARY
        > -   TEXT
        > -   BINTEXT


11. Apply filter conditions on dimensions in the source dataset, and project only the filtered values.

    1.  Open the *Source* tab.

    2.  Select :pencil2: in the *Filters* text box.

        > ### Remember:  
        > You can define filters only after you map columns to the target.

    3.  Select the dimension, and define the filter condition in the *Provide Filter Values* dialog box.

    4.  Select *OK*.


12. **Optional:** Define partitions.

    To optimize the data transfer operation for SAP HANA views, the Modeler provides capabilities to define a maximum of two partition conditions for columns in the source dataset. It supports the following partition types to define the partition condition: List and Range.

    1.  Choose *Add Condition* in the *Partition Conditions* section.

    2.  Select the required partition column and its data type.

    3.  Select the required partition type from the *Type* list.

    4.  Define one or more partition values in the *Partition Values* text box.

        For range partition type, define only the low boundary value.


    > ### Note:  
    > If data is retrieved using the SAP BW OLAP Interface provider \(INA\) as the transfer mode, then the Modeler ignores the partitions.

13. Define the cloud storage target in the *Target* pane.

    To use any of the supported cloud storages as the target dataset for data transfer, provide details about the required cloud storage.

    1.  Enter or browse for a connection ID that provides a connection to the required cloud storage in the *Connection ID* text box.

    2.  Enter or browse for the path of the file to which the graph transfers the data in the *Target* text field.

        If the selected connection has a root path specified in the connection definition, then the content of this field is relative to the path.

        > ### Note:  
        > The Modeler supports CSV, ORC, or Parquet file formats.

    3.  Define a file as a target for *Delta* extraction mode.

        The application supports three modes to write deltas to files as described in the following table.


        <table>
        <tr>
        <th valign="top">

        Mode
        
        </th>
        <th valign="top">

        Description
        
        </th>
        </tr>
        <tr>
        <td valign="top">
        
        *Append*
        
        </td>
        <td valign="top">
        
        Choose a file or select a file name in the target file system. Each delta run is appended to the selected file.
        
        </td>
        </tr>
        <tr>
        <td valign="top">
        
        *Create*
        
        </td>
        <td valign="top">
        
        Choose a folder in the target file system. Each delta run creates a new file in the selected folder.

        In *Create* mode, you must define the `fileNamePattern` property that tells how the delta files are to be created inside the folder.

        > ### Example:  
        > <code>Customer-<i class="varname">&lt;date&gt;</i>-<i class="varname">&lt;time&gt;</i></code>, where, Customer is the name of the source dataset.


        
        </td>
        </tr>
        <tr>
        <td valign="top">
        
        *Create for each package*
        
        </td>
        <td valign="top">
        
        Choose a file or pick a file name in the target file system. Each delta run writes a new file for each data package.
        
        </td>
        </tr>
        </table>
        
        > ### Note:  
        > SAP Data Intelligence supports only the `.csv` file format for delta write mode.

    4.  **Optional:** Select *Fetch Metadata* only if you manually entered the file path in the top right of the editor.

        The *Fetch Metadata* functionality helps to fetch the metadata \(schema\) from the selected source or target and populates the column details accordingly in the Modeler.


14. Map source and target columns.

    1.  Open the *Target* tab.

    2.  Select a source column from the source and drag it to the target column in the *Column Mapping* section.

        Use the mapping editor.


15. **Optional:** After you complete the mapping, preview data.

    1.  Open the *Source* tab.

    2.  Select *Data Preview*.

        The following table describes the areas to preview.


        <table>
        <tr>
        <th valign="top">

        Area
        
        </th>
        <th valign="top">

        Description
        
        </th>
        </tr>
        <tr>
        <td valign="top">
        
        *Source Data*
        
        </td>
        <td valign="top">
        
        Preview remote dataset. Enter variable values to see the data preview.
        
        </td>
        </tr>
        <tr>
        <td valign="top">
        
        *Adapted Data*
        
        </td>
        <td valign="top">
        
        Preview the selected columns in the *Target* tab, the variable values that you entered, and the filters that you provided.
        
        </td>
        </tr>
        </table>
        
    3.  Open the *Target* tab.

    4.  Select *Data Preview*.

        View data similar to data in the *Source* tab.

        > ### Note:  
        > When you run the data transfer graph, only the mapped columns are projected to the target dataset.


16. Save and run the graph.

    You can control the start and stop of the graph execution using the Workflow Trigger and Workflow Terminator operators respectively.

    > ### Tip:  
    > You can also schedule the graph run. For more information, see [Schedule Graph Executions](../using-graphs/schedule-graph-executions-cb46d5f.md).


-   **[Transfer Modes](transfer-modes-a615280.md "The Data Transfer operator in SAP Data Intelligence
		supports different modes for retrieving data. ")**  
The Data Transfer operator in SAP Data Intelligence supports different modes for retrieving data.

**Related Information**  


[Working with the Data Workflow Operators](working-with-the-data-workflow-operators-f3f4333.md "SAP Data Intelligence Modeler has a category of operators called Data Workflow operators. When used in a graph (pipeline) and executed, the Data Workflow operators run for a limited time and finish with the status of either “completed” or “dead”.")

[Create a Connection](https://help.sap.com/viewer/300d97f4d57c4b329df8c83858ff67fb/Dev/en-US/e259041c90734cb688e13a7931e7d721.html "Create a connection in SAP Data Intelligence, which represents an access point to a remote system or a remote data source.") :arrow_upper_right:

