<!-- loio4a0bd34bc25847a1928bea2971a0a6fe -->

# TensorFlow 2 and Scikit

The TensorFlow 2 and Scikit Structured Data Classification template illustrates how to use the Training operator to train a structured data classification model with TensorFlow 2, and to submit metrics in an ML scenario. It uses a small dataset provided by the Cleveland Clinic Foundation for Heart Disease.



Because the dataset is in the order of less than a Megabyte, it is downloaded just before use. The dataset is a single `CSV` file.

Pandas is used to read the file from the URL and create a dataset that TensorFlow 2 will use. Scikit \(sklearn\) is used with the `train_test_split` function to split the dataset into training, test, and validation parts. TensorFlow 2 is used through Keras to do the training and produce a trained model that is saved as an artifact via the HEARTMODEL output port of the operator. The *Training* operator uses the basic resource plan and a docker image tailored for running TensorFlow 2 on CPUs for the training. In addition, logs generated by the training script are sent via the logs output port. A Python3 operator *Metrics Extractor* is used to extract metrics from the training logs. The extracted metrics are delivered to the *Submit Metrics* operator, which registers the metrics as part of the scenario.

The *Training* operator outputs the model artifact only after all logs generated during training have been output. When the message representing the model artifact is delivered to the *Workflow Terminator*, the graph will complete.



<a name="loio4a0bd34bc25847a1928bea2971a0a6fe__section_nsl_vyb_vmb"/>

## Configure and Run the Graph

1.  In your ML scenario, choose the *Pipelines* tab.
2.  Click *Create* to add a pipeline.
3.  Enter a name for your pipeline and select the *Tensorflow 2 and scikit structured data classification* template from the dropdown list;
4.  Click *Create*.
5.  Select your pipeline from the list and click *Execute*.



<a name="loio4a0bd34bc25847a1928bea2971a0a6fe__section_aqz_vyb_vmb"/>

## Managing Artifacts in Training

The training script uses the Python SDK `sapdi` to manage artifacts as follows:

```py
import sapdi
from sapdi.artifact.artifact import Artifact, ArtifactKind, ArtifactFileType
```



<a name="loio4a0bd34bc25847a1928bea2971a0a6fe__section_s31_wyb_vmb"/>

## Creating Artifact for the Trained Model

```py
118. out_artifact = sapdi.create_artifact(
"HEARTMODEL", 
file_type=ArtifactFileType.ZIP,
description="Tensorflow 2 structured data classification model",
artifact_name="HEART_STRUCTURED_DATA_CLASSIFICATION_MODEL",
artifact_kind=ArtifactKind.MODEL
)
model_path = out_artifact.get_path()
model.save(model_path, save_format='tf')
move_model(model_path)
```

